{
 "metadata": {
  "name": "project_presentation",
  "kernelspec": {
   "language": "scala",
   "name": "spark2-scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "val filePath = \"bitcoin-clean.parquet\"\n",
    "val rawDF = spark.read\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"multiLine\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .option(\"escape\", \"\\\"\")\n",
    "  .parquet(filePath)\n",
    "\n",
    "z.show(rawDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "z.show(rawDF.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "// val outputPath = \"bitcoin_clean.csv\"\n",
    "// rawDF.write.mode(\"overwrite\").csv(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "// convert to daily frequency\n",
    "val dateDF = rawDF.withColumn(\"date\", to_date(col(\"index\"))).sort(\"date\")\n",
    "                .groupBy($\"date\").agg(first(\"Open\"), last(\"Close\"), max(\"High\"), min(\"Low\"), sum(\"btc_volume\"), sum(\"usd_volume\"), stddev(\"return\").alias(\"volatility\"), count(\"*\").alias(\"cnt\"))\n",
    "\n",
    "z.show(dateDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "dateDF.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "z.show(dateDF.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "z.show(dateDF.sort(\"volatility\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "val dayDF = dateDF\n",
    "            .withColumnRenamed(\"first(Open)\", \"open\")\n",
    "            .withColumnRenamed(\"last(Close)\", \"close\")\n",
    "            .withColumnRenamed(\"max(High)\", \"high\")\n",
    "            .withColumnRenamed(\"min(Low)\", \"low\")\n",
    "            .withColumnRenamed(\"sum(btc_volume)\", \"btc_volume\")\n",
    "            .withColumnRenamed(\"sum(usd_volume)\", \"usd_volume\")\n",
    "            .sort($\"date\")\n",
    "dayDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "z.show(dayDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "z.show(dayDF.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.expressions.Window\n",
    "val w = Window.orderBy(\"date\")\n",
    "val retDF = dayDF.withColumn(\"ret\", (col(\"close\") - lag(\"close\", 1).over(w)) / lag(\"close\", 1).over(w))\n",
    "                .na.drop(\"any\")\n",
    "z.show(retDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "val filteredDF = retDF.filter(col(\"date\") >= \"2016-01-01\" && col(\"date\") <= \"2019-05-01\")\n",
    "z.show(filteredDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "z.show(filteredDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "z.show(filteredDF.select(\"date\", \"Close\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "val outputPath = \"bitcoin_filtered\"\n",
    "filteredDF.write.option(\"header\",true).mode(\"overwrite\").csv(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%sh pip install plotly"
   ]
  }
 ]
}
